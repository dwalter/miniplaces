('# Images found:', 100000)
('# Images found:', 10000)
[2017-11-20 19:33:17]:
-Iter 0, Training Loss= 2.666713, Accuracy Top1 = 0.3594, Top5 = 0.6406
-Iter 0, Validation Loss= 2.963838, Accuracy Top1 = 0.2891, Top5 = 0.5547
[2017-11-20 19:34:45]:
-Iter 50, Training Loss= 2.639025, Accuracy Top1 = 0.3906, Top5 = 0.6406
-Iter 50, Validation Loss= 3.030466, Accuracy Top1 = 0.2969, Top5 = 0.5625
[2017-11-20 19:35:53]:
-Iter 100, Training Loss= 2.602527, Accuracy Top1 = 0.3516, Top5 = 0.6719
-Iter 100, Validation Loss= 2.813561, Accuracy Top1 = 0.2969, Top5 = 0.5938
[2017-11-20 19:37:01]:
-Iter 150, Training Loss= 2.518776, Accuracy Top1 = 0.3906, Top5 = 0.5938
-Iter 150, Validation Loss= 2.952446, Accuracy Top1 = 0.3359, Top5 = 0.5547
[2017-11-20 19:38:09]:
-Iter 200, Training Loss= 2.463453, Accuracy Top1 = 0.3750, Top5 = 0.6562
-Iter 200, Validation Loss= 2.939638, Accuracy Top1 = 0.2578, Top5 = 0.5547
[2017-11-20 19:39:17]:
-Iter 250, Training Loss= 2.528506, Accuracy Top1 = 0.3672, Top5 = 0.6719
-Iter 250, Validation Loss= 2.948981, Accuracy Top1 = 0.2891, Top5 = 0.5781
[2017-11-20 19:40:25]:
-Iter 300, Training Loss= 2.480217, Accuracy Top1 = 0.3984, Top5 = 0.6406
-Iter 300, Validation Loss= 2.755398, Accuracy Top1 = 0.2812, Top5 = 0.5859
[2017-11-20 19:41:33]:
-Iter 350, Training Loss= 2.769629, Accuracy Top1 = 0.2734, Top5 = 0.6406
-Iter 350, Validation Loss= 2.776362, Accuracy Top1 = 0.3047, Top5 = 0.5859
[2017-11-20 19:42:41]:
-Iter 400, Training Loss= 2.477560, Accuracy Top1 = 0.3906, Top5 = 0.6875
-Iter 400, Validation Loss= 2.864777, Accuracy Top1 = 0.3125, Top5 = 0.6016
[2017-11-20 19:43:48]:
-Iter 450, Training Loss= 2.588781, Accuracy Top1 = 0.3281, Top5 = 0.6484
-Iter 450, Validation Loss= 2.736278, Accuracy Top1 = 0.2656, Top5 = 0.6328
[2017-11-20 19:44:56]:
-Iter 500, Training Loss= 2.625502, Accuracy Top1 = 0.3516, Top5 = 0.6250
-Iter 500, Validation Loss= 2.929612, Accuracy Top1 = 0.3438, Top5 = 0.5703
[2017-11-20 19:46:04]:
-Iter 550, Training Loss= 2.679197, Accuracy Top1 = 0.3359, Top5 = 0.6328
-Iter 550, Validation Loss= 3.317055, Accuracy Top1 = 0.1875, Top5 = 0.5000
[2017-11-20 19:47:11]:
-Iter 600, Training Loss= 2.634260, Accuracy Top1 = 0.2812, Top5 = 0.6484
-Iter 600, Validation Loss= 2.935957, Accuracy Top1 = 0.2578, Top5 = 0.5391
[2017-11-20 19:48:19]:
-Iter 650, Training Loss= 2.797935, Accuracy Top1 = 0.3047, Top5 = 0.6172
-Iter 650, Validation Loss= 2.840389, Accuracy Top1 = 0.2969, Top5 = 0.5703
[2017-11-20 19:49:26]:
-Iter 700, Training Loss= 2.734204, Accuracy Top1 = 0.3438, Top5 = 0.5859
-Iter 700, Validation Loss= 2.901535, Accuracy Top1 = 0.2578, Top5 = 0.5469
[2017-11-20 19:50:34]:
-Iter 750, Training Loss= 2.845777, Accuracy Top1 = 0.2656, Top5 = 0.5859
-Iter 750, Validation Loss= 3.132144, Accuracy Top1 = 0.3047, Top5 = 0.5234
[2017-11-20 19:51:41]:
-Iter 800, Training Loss= 2.585521, Accuracy Top1 = 0.3125, Top5 = 0.6797
-Iter 800, Validation Loss= 2.854119, Accuracy Top1 = 0.2578, Top5 = 0.6328
[2017-11-20 19:52:49]:
-Iter 850, Training Loss= 2.364436, Accuracy Top1 = 0.3984, Top5 = 0.7109
-Iter 850, Validation Loss= 2.798638, Accuracy Top1 = 0.2656, Top5 = 0.5859
[2017-11-20 19:53:57]:
-Iter 900, Training Loss= 2.711529, Accuracy Top1 = 0.3438, Top5 = 0.6094
-Iter 900, Validation Loss= 3.078713, Accuracy Top1 = 0.2500, Top5 = 0.5703
[2017-11-20 19:55:04]:
-Iter 950, Training Loss= 2.772439, Accuracy Top1 = 0.3047, Top5 = 0.5781
-Iter 950, Validation Loss= 3.021645, Accuracy Top1 = 0.2500, Top5 = 0.4922
[2017-11-20 19:56:12]:
-Iter 1000, Training Loss= 2.420988, Accuracy Top1 = 0.3906, Top5 = 0.6641
-Iter 1000, Validation Loss= 2.450468, Accuracy Top1 = 0.3594, Top5 = 0.6484
[2017-11-20 19:57:19]:
-Iter 1050, Training Loss= 2.684774, Accuracy Top1 = 0.3125, Top5 = 0.6172
-Iter 1050, Validation Loss= 2.828636, Accuracy Top1 = 0.3047, Top5 = 0.6172
[2017-11-20 19:58:27]:
-Iter 1100, Training Loss= 2.775203, Accuracy Top1 = 0.3203, Top5 = 0.6328
-Iter 1100, Validation Loss= 2.943154, Accuracy Top1 = 0.2734, Top5 = 0.5469
[2017-11-20 19:59:34]:
-Iter 1150, Training Loss= 2.662351, Accuracy Top1 = 0.3359, Top5 = 0.5859
-Iter 1150, Validation Loss= 2.866405, Accuracy Top1 = 0.2891, Top5 = 0.5781
[2017-11-20 20:00:42]:
-Iter 1200, Training Loss= 2.717545, Accuracy Top1 = 0.3438, Top5 = 0.5938
-Iter 1200, Validation Loss= 2.877154, Accuracy Top1 = 0.2891, Top5 = 0.5859
[2017-11-20 20:01:49]:
-Iter 1250, Training Loss= 2.547516, Accuracy Top1 = 0.3438, Top5 = 0.6484
-Iter 1250, Validation Loss= 3.001505, Accuracy Top1 = 0.2812, Top5 = 0.5547
[2017-11-20 20:02:57]:
-Iter 1300, Training Loss= 2.732568, Accuracy Top1 = 0.3203, Top5 = 0.6016
-Iter 1300, Validation Loss= 2.895481, Accuracy Top1 = 0.2969, Top5 = 0.6016
[2017-11-20 20:04:04]:
-Iter 1350, Training Loss= 2.871727, Accuracy Top1 = 0.3125, Top5 = 0.5547
-Iter 1350, Validation Loss= 2.987594, Accuracy Top1 = 0.2344, Top5 = 0.5625
[2017-11-20 20:05:11]:
-Iter 1400, Training Loss= 2.685203, Accuracy Top1 = 0.3281, Top5 = 0.6328
-Iter 1400, Validation Loss= 3.074976, Accuracy Top1 = 0.2891, Top5 = 0.5156
[2017-11-20 20:06:19]:
-Iter 1450, Training Loss= 2.628671, Accuracy Top1 = 0.3672, Top5 = 0.6328
-Iter 1450, Validation Loss= 2.756042, Accuracy Top1 = 0.2891, Top5 = 0.5938
[2017-11-20 20:07:26]:
-Iter 1500, Training Loss= 2.688122, Accuracy Top1 = 0.2891, Top5 = 0.6094
-Iter 1500, Validation Loss= 2.947187, Accuracy Top1 = 0.3125, Top5 = 0.5547
[2017-11-20 20:08:34]:
-Iter 1550, Training Loss= 2.595308, Accuracy Top1 = 0.3359, Top5 = 0.6484
-Iter 1550, Validation Loss= 2.686109, Accuracy Top1 = 0.3047, Top5 = 0.5938
[2017-11-20 20:09:41]:
-Iter 1600, Training Loss= 2.596052, Accuracy Top1 = 0.3281, Top5 = 0.6406
-Iter 1600, Validation Loss= 2.846122, Accuracy Top1 = 0.2969, Top5 = 0.6328
[2017-11-20 20:10:48]:
-Iter 1650, Training Loss= 2.483515, Accuracy Top1 = 0.3359, Top5 = 0.6641
-Iter 1650, Validation Loss= 2.927799, Accuracy Top1 = 0.2812, Top5 = 0.5703
[2017-11-20 20:11:56]:
-Iter 1700, Training Loss= 2.484754, Accuracy Top1 = 0.3828, Top5 = 0.6094
-Iter 1700, Validation Loss= 2.592159, Accuracy Top1 = 0.3359, Top5 = 0.6484
[2017-11-20 20:13:03]:
-Iter 1750, Training Loss= 2.865023, Accuracy Top1 = 0.3047, Top5 = 0.5234
-Iter 1750, Validation Loss= 2.636530, Accuracy Top1 = 0.2969, Top5 = 0.5859
[2017-11-20 20:14:11]:
-Iter 1800, Training Loss= 2.709287, Accuracy Top1 = 0.3516, Top5 = 0.6016
-Iter 1800, Validation Loss= 3.039325, Accuracy Top1 = 0.2500, Top5 = 0.5234
[2017-11-20 20:15:18]:
-Iter 1850, Training Loss= 2.598569, Accuracy Top1 = 0.3281, Top5 = 0.6562
-Iter 1850, Validation Loss= 2.836312, Accuracy Top1 = 0.2812, Top5 = 0.5547
[2017-11-20 20:16:26]:
-Iter 1900, Training Loss= 2.657216, Accuracy Top1 = 0.3203, Top5 = 0.6641
-Iter 1900, Validation Loss= 2.726700, Accuracy Top1 = 0.2734, Top5 = 0.6094
[2017-11-20 20:17:33]:
-Iter 1950, Training Loss= 2.638090, Accuracy Top1 = 0.3281, Top5 = 0.6094
-Iter 1950, Validation Loss= 2.889854, Accuracy Top1 = 0.2500, Top5 = 0.5312
[2017-11-20 20:18:40]:
-Iter 2000, Training Loss= 2.462610, Accuracy Top1 = 0.3281, Top5 = 0.6641
-Iter 2000, Validation Loss= 2.585522, Accuracy Top1 = 0.2969, Top5 = 0.6094
[2017-11-20 20:19:48]:
-Iter 2050, Training Loss= 2.613520, Accuracy Top1 = 0.4219, Top5 = 0.6328
-Iter 2050, Validation Loss= 2.748640, Accuracy Top1 = 0.3125, Top5 = 0.6016
[2017-11-20 20:20:55]:
-Iter 2100, Training Loss= 2.828403, Accuracy Top1 = 0.2812, Top5 = 0.5938
-Iter 2100, Validation Loss= 2.704715, Accuracy Top1 = 0.3594, Top5 = 0.6172
[2017-11-20 20:22:03]:
-Iter 2150, Training Loss= 2.785499, Accuracy Top1 = 0.3125, Top5 = 0.6094
-Iter 2150, Validation Loss= 2.837711, Accuracy Top1 = 0.3359, Top5 = 0.5391
[2017-11-20 20:23:10]:
-Iter 2200, Training Loss= 2.694348, Accuracy Top1 = 0.2734, Top5 = 0.6562
-Iter 2200, Validation Loss= 2.718692, Accuracy Top1 = 0.3203, Top5 = 0.5859
[2017-11-20 20:24:17]:
-Iter 2250, Training Loss= 2.450097, Accuracy Top1 = 0.3750, Top5 = 0.6797
-Iter 2250, Validation Loss= 2.834098, Accuracy Top1 = 0.3125, Top5 = 0.5547
[2017-11-20 20:25:25]:
-Iter 2300, Training Loss= 2.351079, Accuracy Top1 = 0.4141, Top5 = 0.6797
-Iter 2300, Validation Loss= 2.887060, Accuracy Top1 = 0.2109, Top5 = 0.5469
[2017-11-20 20:26:32]:
-Iter 2350, Training Loss= 2.608434, Accuracy Top1 = 0.3516, Top5 = 0.6953
-Iter 2350, Validation Loss= 3.039318, Accuracy Top1 = 0.2422, Top5 = 0.5312
[2017-11-20 20:27:40]:
-Iter 2400, Training Loss= 2.574322, Accuracy Top1 = 0.3828, Top5 = 0.6797
-Iter 2400, Validation Loss= 3.018558, Accuracy Top1 = 0.2422, Top5 = 0.5625
[2017-11-20 20:28:47]:
-Iter 2450, Training Loss= 2.686618, Accuracy Top1 = 0.3203, Top5 = 0.6016
-Iter 2450, Validation Loss= 2.671562, Accuracy Top1 = 0.3125, Top5 = 0.6172
[2017-11-20 20:29:54]:
-Iter 2500, Training Loss= 2.577830, Accuracy Top1 = 0.3438, Top5 = 0.6719
-Iter 2500, Validation Loss= 2.839647, Accuracy Top1 = 0.2734, Top5 = 0.5391
[2017-11-20 20:31:02]:
-Iter 2550, Training Loss= 2.364614, Accuracy Top1 = 0.4141, Top5 = 0.7188
-Iter 2550, Validation Loss= 2.864946, Accuracy Top1 = 0.3281, Top5 = 0.5625
[2017-11-20 20:32:09]:
-Iter 2600, Training Loss= 2.464975, Accuracy Top1 = 0.3750, Top5 = 0.7031
-Iter 2600, Validation Loss= 3.008697, Accuracy Top1 = 0.2656, Top5 = 0.5625
[2017-11-20 20:33:17]:
-Iter 2650, Training Loss= 2.662146, Accuracy Top1 = 0.3125, Top5 = 0.6484
-Iter 2650, Validation Loss= 2.729376, Accuracy Top1 = 0.3125, Top5 = 0.5781
[2017-11-20 20:34:24]:
-Iter 2700, Training Loss= 2.635346, Accuracy Top1 = 0.3359, Top5 = 0.6328
-Iter 2700, Validation Loss= 3.077544, Accuracy Top1 = 0.2109, Top5 = 0.5547
[2017-11-20 20:35:31]:
-Iter 2750, Training Loss= 2.469865, Accuracy Top1 = 0.3828, Top5 = 0.6797
-Iter 2750, Validation Loss= 2.947813, Accuracy Top1 = 0.2812, Top5 = 0.5234
[2017-11-20 20:36:39]:
-Iter 2800, Training Loss= 2.647040, Accuracy Top1 = 0.3125, Top5 = 0.6328
-Iter 2800, Validation Loss= 2.850400, Accuracy Top1 = 0.2500, Top5 = 0.6016
[2017-11-20 20:37:46]:
-Iter 2850, Training Loss= 2.749315, Accuracy Top1 = 0.3359, Top5 = 0.6094
-Iter 2850, Validation Loss= 2.379169, Accuracy Top1 = 0.3594, Top5 = 0.6719
[2017-11-20 20:38:53]:
-Iter 2900, Training Loss= 2.654356, Accuracy Top1 = 0.3594, Top5 = 0.6797
-Iter 2900, Validation Loss= 2.900877, Accuracy Top1 = 0.2812, Top5 = 0.5781
[2017-11-20 20:40:01]:
-Iter 2950, Training Loss= 2.564847, Accuracy Top1 = 0.3359, Top5 = 0.6641
-Iter 2950, Validation Loss= 2.963942, Accuracy Top1 = 0.2812, Top5 = 0.5625
[2017-11-20 20:41:08]:
-Iter 3000, Training Loss= 2.500146, Accuracy Top1 = 0.4062, Top5 = 0.6172
-Iter 3000, Validation Loss= 3.188944, Accuracy Top1 = 0.2266, Top5 = 0.5156
[2017-11-20 20:42:15]:
-Iter 3050, Training Loss= 2.555106, Accuracy Top1 = 0.3750, Top5 = 0.6406
-Iter 3050, Validation Loss= 3.089789, Accuracy Top1 = 0.2500, Top5 = 0.5312
[2017-11-20 20:43:23]:
-Iter 3100, Training Loss= 2.561938, Accuracy Top1 = 0.3203, Top5 = 0.7031
-Iter 3100, Validation Loss= 3.037356, Accuracy Top1 = 0.3047, Top5 = 0.5156
[2017-11-20 20:44:30]:
-Iter 3150, Training Loss= 2.728350, Accuracy Top1 = 0.3203, Top5 = 0.6562
-Iter 3150, Validation Loss= 2.718478, Accuracy Top1 = 0.2891, Top5 = 0.6016
[2017-11-20 20:45:37]:
-Iter 3200, Training Loss= 2.562832, Accuracy Top1 = 0.3125, Top5 = 0.6641
-Iter 3200, Validation Loss= 2.716600, Accuracy Top1 = 0.3281, Top5 = 0.6016
[2017-11-20 20:46:45]:
-Iter 3250, Training Loss= 2.544874, Accuracy Top1 = 0.4062, Top5 = 0.6250
-Iter 3250, Validation Loss= 2.465136, Accuracy Top1 = 0.3438, Top5 = 0.6797
[2017-11-20 20:47:52]:
-Iter 3300, Training Loss= 2.517092, Accuracy Top1 = 0.3828, Top5 = 0.6406
-Iter 3300, Validation Loss= 2.909962, Accuracy Top1 = 0.2734, Top5 = 0.5703
[2017-11-20 20:48:59]:
-Iter 3350, Training Loss= 2.585359, Accuracy Top1 = 0.3516, Top5 = 0.6484
-Iter 3350, Validation Loss= 2.770703, Accuracy Top1 = 0.3281, Top5 = 0.5859
[2017-11-20 20:50:07]:
-Iter 3400, Training Loss= 2.524115, Accuracy Top1 = 0.3203, Top5 = 0.6328
-Iter 3400, Validation Loss= 2.527693, Accuracy Top1 = 0.4297, Top5 = 0.5938
[2017-11-20 20:51:14]:
-Iter 3450, Training Loss= 2.482275, Accuracy Top1 = 0.3594, Top5 = 0.7031
-Iter 3450, Validation Loss= 2.747323, Accuracy Top1 = 0.3281, Top5 = 0.6562
[2017-11-20 20:52:22]:
-Iter 3500, Training Loss= 2.704444, Accuracy Top1 = 0.3047, Top5 = 0.5859
-Iter 3500, Validation Loss= 2.810309, Accuracy Top1 = 0.3125, Top5 = 0.5781
[2017-11-20 20:53:29]:
-Iter 3550, Training Loss= 2.354943, Accuracy Top1 = 0.3984, Top5 = 0.7266
-Iter 3550, Validation Loss= 2.398533, Accuracy Top1 = 0.3906, Top5 = 0.7109
[2017-11-20 20:54:36]:
-Iter 3600, Training Loss= 2.781361, Accuracy Top1 = 0.3125, Top5 = 0.6172
-Iter 3600, Validation Loss= 2.763185, Accuracy Top1 = 0.3594, Top5 = 0.5859
[2017-11-20 20:55:44]:
-Iter 3650, Training Loss= 2.669613, Accuracy Top1 = 0.3359, Top5 = 0.6562
-Iter 3650, Validation Loss= 3.201031, Accuracy Top1 = 0.2969, Top5 = 0.5156
[2017-11-20 20:56:51]:
-Iter 3700, Training Loss= 2.561415, Accuracy Top1 = 0.3359, Top5 = 0.6094
-Iter 3700, Validation Loss= 2.705562, Accuracy Top1 = 0.2891, Top5 = 0.6406
[2017-11-20 20:57:58]:
-Iter 3750, Training Loss= 2.421111, Accuracy Top1 = 0.4062, Top5 = 0.6719
-Iter 3750, Validation Loss= 2.873079, Accuracy Top1 = 0.2578, Top5 = 0.4844
[2017-11-20 20:59:06]:
-Iter 3800, Training Loss= 2.616194, Accuracy Top1 = 0.3516, Top5 = 0.6328
-Iter 3800, Validation Loss= 2.838984, Accuracy Top1 = 0.2969, Top5 = 0.6562
[2017-11-20 21:00:13]:
-Iter 3850, Training Loss= 2.468745, Accuracy Top1 = 0.3203, Top5 = 0.7031
-Iter 3850, Validation Loss= 2.839312, Accuracy Top1 = 0.2891, Top5 = 0.5781
[2017-11-20 21:01:21]:
-Iter 3900, Training Loss= 2.839410, Accuracy Top1 = 0.3047, Top5 = 0.6016
-Iter 3900, Validation Loss= 2.918686, Accuracy Top1 = 0.2578, Top5 = 0.5547
[2017-11-20 21:02:28]:
-Iter 3950, Training Loss= 2.819629, Accuracy Top1 = 0.2734, Top5 = 0.5781
-Iter 3950, Validation Loss= 3.026234, Accuracy Top1 = 0.3047, Top5 = 0.5859
[2017-11-20 21:03:35]:
-Iter 4000, Training Loss= 2.495306, Accuracy Top1 = 0.4141, Top5 = 0.6719
-Iter 4000, Validation Loss= 2.850596, Accuracy Top1 = 0.2656, Top5 = 0.5469
[2017-11-20 21:04:43]:
-Iter 4050, Training Loss= 2.538573, Accuracy Top1 = 0.3438, Top5 = 0.6484
-Iter 4050, Validation Loss= 2.892867, Accuracy Top1 = 0.3672, Top5 = 0.5625
[2017-11-20 21:05:50]:
-Iter 4100, Training Loss= 2.621294, Accuracy Top1 = 0.3047, Top5 = 0.6641
-Iter 4100, Validation Loss= 2.882139, Accuracy Top1 = 0.2734, Top5 = 0.5547
[2017-11-20 21:06:58]:
-Iter 4150, Training Loss= 2.646696, Accuracy Top1 = 0.3828, Top5 = 0.6172
-Iter 4150, Validation Loss= 2.989159, Accuracy Top1 = 0.2578, Top5 = 0.5547
[2017-11-20 21:08:05]:
-Iter 4200, Training Loss= 2.487684, Accuracy Top1 = 0.4062, Top5 = 0.6562
-Iter 4200, Validation Loss= 2.729817, Accuracy Top1 = 0.3047, Top5 = 0.6016
[2017-11-20 21:09:12]:
-Iter 4250, Training Loss= 2.806674, Accuracy Top1 = 0.2969, Top5 = 0.5938
-Iter 4250, Validation Loss= 2.826641, Accuracy Top1 = 0.2656, Top5 = 0.6016
[2017-11-20 21:10:20]:
-Iter 4300, Training Loss= 2.322638, Accuracy Top1 = 0.4141, Top5 = 0.7188
-Iter 4300, Validation Loss= 2.693877, Accuracy Top1 = 0.3672, Top5 = 0.6484
[2017-11-20 21:11:27]:
-Iter 4350, Training Loss= 2.495517, Accuracy Top1 = 0.3672, Top5 = 0.6641
-Iter 4350, Validation Loss= 2.803733, Accuracy Top1 = 0.2734, Top5 = 0.6094
[2017-11-20 21:12:34]:
-Iter 4400, Training Loss= 2.533698, Accuracy Top1 = 0.3359, Top5 = 0.6875
-Iter 4400, Validation Loss= 2.916569, Accuracy Top1 = 0.3203, Top5 = 0.5625
[2017-11-20 21:13:42]:
-Iter 4450, Training Loss= 2.504982, Accuracy Top1 = 0.3438, Top5 = 0.6562
-Iter 4450, Validation Loss= 3.262807, Accuracy Top1 = 0.2031, Top5 = 0.5312
[2017-11-20 21:14:49]:
-Iter 4500, Training Loss= 2.598500, Accuracy Top1 = 0.3516, Top5 = 0.6953
-Iter 4500, Validation Loss= 2.899483, Accuracy Top1 = 0.2656, Top5 = 0.5547
[2017-11-20 21:15:56]:
-Iter 4550, Training Loss= 2.659309, Accuracy Top1 = 0.3047, Top5 = 0.5938
-Iter 4550, Validation Loss= 2.769426, Accuracy Top1 = 0.3359, Top5 = 0.6172
[2017-11-20 21:17:04]:
-Iter 4600, Training Loss= 2.369309, Accuracy Top1 = 0.4297, Top5 = 0.6797
-Iter 4600, Validation Loss= 2.926226, Accuracy Top1 = 0.2734, Top5 = 0.5469
[2017-11-20 21:18:11]:
-Iter 4650, Training Loss= 2.644368, Accuracy Top1 = 0.3359, Top5 = 0.6250
-Iter 4650, Validation Loss= 3.116228, Accuracy Top1 = 0.3047, Top5 = 0.4922
[2017-11-20 21:19:18]:
-Iter 4700, Training Loss= 2.573997, Accuracy Top1 = 0.3359, Top5 = 0.6484
-Iter 4700, Validation Loss= 2.862723, Accuracy Top1 = 0.2578, Top5 = 0.6250
[2017-11-20 21:20:26]:
-Iter 4750, Training Loss= 2.417976, Accuracy Top1 = 0.3594, Top5 = 0.6953
-Iter 4750, Validation Loss= 2.835262, Accuracy Top1 = 0.2344, Top5 = 0.5938
[2017-11-20 21:21:33]:
-Iter 4800, Training Loss= 2.317358, Accuracy Top1 = 0.3984, Top5 = 0.7344
-Iter 4800, Validation Loss= 2.884958, Accuracy Top1 = 0.2812, Top5 = 0.5938
[2017-11-20 21:22:41]:
-Iter 4850, Training Loss= 2.373255, Accuracy Top1 = 0.3594, Top5 = 0.6797
-Iter 4850, Validation Loss= 3.024577, Accuracy Top1 = 0.2422, Top5 = 0.5234
[2017-11-20 21:23:48]:
-Iter 4900, Training Loss= 2.290965, Accuracy Top1 = 0.3594, Top5 = 0.7500
-Iter 4900, Validation Loss= 2.605948, Accuracy Top1 = 0.3438, Top5 = 0.6406
[2017-11-20 21:24:55]:
-Iter 4950, Training Loss= 2.535530, Accuracy Top1 = 0.3672, Top5 = 0.6484
-Iter 4950, Validation Loss= 2.739552, Accuracy Top1 = 0.3281, Top5 = 0.6172
[2017-11-20 21:26:03]:
-Iter 5000, Training Loss= 2.660787, Accuracy Top1 = 0.2734, Top5 = 0.5938
-Iter 5000, Validation Loss= 2.977166, Accuracy Top1 = 0.2422, Top5 = 0.5703
[2017-11-20 21:27:10]:
-Iter 5050, Training Loss= 2.549369, Accuracy Top1 = 0.3828, Top5 = 0.6875
-Iter 5050, Validation Loss= 2.788190, Accuracy Top1 = 0.3047, Top5 = 0.5625
[2017-11-20 21:28:18]:
-Iter 5100, Training Loss= 2.301569, Accuracy Top1 = 0.4062, Top5 = 0.6641
-Iter 5100, Validation Loss= 2.838897, Accuracy Top1 = 0.2812, Top5 = 0.5703
[2017-11-20 21:29:25]:
-Iter 5150, Training Loss= 2.540002, Accuracy Top1 = 0.3906, Top5 = 0.7031
-Iter 5150, Validation Loss= 3.029006, Accuracy Top1 = 0.3047, Top5 = 0.5469
[2017-11-20 21:30:32]:
-Iter 5200, Training Loss= 2.680172, Accuracy Top1 = 0.3828, Top5 = 0.6641
-Iter 5200, Validation Loss= 2.883939, Accuracy Top1 = 0.3047, Top5 = 0.6016
[2017-11-20 21:31:40]:
-Iter 5250, Training Loss= 2.646637, Accuracy Top1 = 0.3047, Top5 = 0.6328
-Iter 5250, Validation Loss= 2.803688, Accuracy Top1 = 0.2578, Top5 = 0.6016
[2017-11-20 21:32:47]:
-Iter 5300, Training Loss= 2.618005, Accuracy Top1 = 0.3438, Top5 = 0.6328
-Iter 5300, Validation Loss= 3.206896, Accuracy Top1 = 0.2656, Top5 = 0.5000
[2017-11-20 21:33:54]:
-Iter 5350, Training Loss= 2.599270, Accuracy Top1 = 0.3828, Top5 = 0.6250
-Iter 5350, Validation Loss= 2.659778, Accuracy Top1 = 0.3359, Top5 = 0.6016
[2017-11-20 21:35:02]:
-Iter 5400, Training Loss= 2.586689, Accuracy Top1 = 0.3125, Top5 = 0.6719
-Iter 5400, Validation Loss= 2.983811, Accuracy Top1 = 0.2734, Top5 = 0.5547
[2017-11-20 21:36:09]:
-Iter 5450, Training Loss= 2.418008, Accuracy Top1 = 0.3984, Top5 = 0.6641
-Iter 5450, Validation Loss= 2.733877, Accuracy Top1 = 0.2891, Top5 = 0.5547
[2017-11-20 21:37:17]:
-Iter 5500, Training Loss= 2.529474, Accuracy Top1 = 0.3906, Top5 = 0.6406
-Iter 5500, Validation Loss= 2.785461, Accuracy Top1 = 0.3203, Top5 = 0.6328
[2017-11-20 21:38:24]:
-Iter 5550, Training Loss= 2.632088, Accuracy Top1 = 0.3125, Top5 = 0.6250
-Iter 5550, Validation Loss= 2.953887, Accuracy Top1 = 0.2812, Top5 = 0.5391
[2017-11-20 21:39:32]:
-Iter 5600, Training Loss= 2.668166, Accuracy Top1 = 0.3125, Top5 = 0.6094
-Iter 5600, Validation Loss= 2.478507, Accuracy Top1 = 0.3672, Top5 = 0.6562
[2017-11-20 21:40:39]:
-Iter 5650, Training Loss= 2.631477, Accuracy Top1 = 0.2969, Top5 = 0.6484
-Iter 5650, Validation Loss= 2.633834, Accuracy Top1 = 0.2969, Top5 = 0.6250
[2017-11-20 21:41:46]:
-Iter 5700, Training Loss= 2.610852, Accuracy Top1 = 0.3672, Top5 = 0.6562
-Iter 5700, Validation Loss= 2.919724, Accuracy Top1 = 0.2578, Top5 = 0.5391
[2017-11-20 21:42:54]:
-Iter 5750, Training Loss= 2.513510, Accuracy Top1 = 0.3438, Top5 = 0.6719
-Iter 5750, Validation Loss= 2.896467, Accuracy Top1 = 0.2891, Top5 = 0.5312
[2017-11-20 21:44:01]:
-Iter 5800, Training Loss= 2.388968, Accuracy Top1 = 0.3984, Top5 = 0.6797
-Iter 5800, Validation Loss= 2.730204, Accuracy Top1 = 0.2812, Top5 = 0.6328
[2017-11-20 21:45:09]:
-Iter 5850, Training Loss= 2.721138, Accuracy Top1 = 0.3516, Top5 = 0.6250
-Iter 5850, Validation Loss= 2.947804, Accuracy Top1 = 0.2109, Top5 = 0.5234
[2017-11-20 21:46:16]:
-Iter 5900, Training Loss= 2.499495, Accuracy Top1 = 0.3672, Top5 = 0.6484
-Iter 5900, Validation Loss= 2.532456, Accuracy Top1 = 0.2969, Top5 = 0.6172
[2017-11-20 21:47:24]:
-Iter 5950, Training Loss= 2.655330, Accuracy Top1 = 0.2969, Top5 = 0.6250
-Iter 5950, Validation Loss= 2.764831, Accuracy Top1 = 0.3359, Top5 = 0.5781
Model saved at Iter 6000 !
[2017-11-20 21:48:40]:
-Iter 6000, Training Loss= 2.758322, Accuracy Top1 = 0.3281, Top5 = 0.6094
-Iter 6000, Validation Loss= 2.626995, Accuracy Top1 = 0.3516, Top5 = 0.6250
Optimization Finished!
Evaluation on the whole validation set...
Validation Accuracy Top1 = 0.2656, Top5 = 0.5859
Validation Accuracy Top1 = 0.2891, Top5 = 0.5781
Validation Accuracy Top1 = 0.3047, Top5 = 0.5781
Validation Accuracy Top1 = 0.3438, Top5 = 0.5547
Validation Accuracy Top1 = 0.2656, Top5 = 0.5312
Validation Accuracy Top1 = 0.2891, Top5 = 0.5938
Validation Accuracy Top1 = 0.3047, Top5 = 0.6016
Validation Accuracy Top1 = 0.3203, Top5 = 0.6094
Validation Accuracy Top1 = 0.3359, Top5 = 0.6328
Validation Accuracy Top1 = 0.2734, Top5 = 0.6406
Validation Accuracy Top1 = 0.3438, Top5 = 0.5703
Validation Accuracy Top1 = 0.1875, Top5 = 0.4922
Validation Accuracy Top1 = 0.2812, Top5 = 0.5625
Validation Accuracy Top1 = 0.3203, Top5 = 0.5938
Validation Accuracy Top1 = 0.2656, Top5 = 0.5469
Validation Accuracy Top1 = 0.2812, Top5 = 0.5156
Validation Accuracy Top1 = 0.2422, Top5 = 0.6172
Validation Accuracy Top1 = 0.2422, Top5 = 0.6016
Validation Accuracy Top1 = 0.2812, Top5 = 0.5703
Validation Accuracy Top1 = 0.2578, Top5 = 0.4922
Validation Accuracy Top1 = 0.3672, Top5 = 0.6797
Validation Accuracy Top1 = 0.3125, Top5 = 0.6094
Validation Accuracy Top1 = 0.2500, Top5 = 0.5547
Validation Accuracy Top1 = 0.2891, Top5 = 0.5625
Validation Accuracy Top1 = 0.2891, Top5 = 0.6016
Validation Accuracy Top1 = 0.2656, Top5 = 0.5469
Validation Accuracy Top1 = 0.2812, Top5 = 0.6250
Validation Accuracy Top1 = 0.2266, Top5 = 0.5625
Validation Accuracy Top1 = 0.2969, Top5 = 0.5391
Validation Accuracy Top1 = 0.3203, Top5 = 0.5859
Validation Accuracy Top1 = 0.3125, Top5 = 0.5547
Validation Accuracy Top1 = 0.2812, Top5 = 0.5938
Validation Accuracy Top1 = 0.3047, Top5 = 0.6250
Validation Accuracy Top1 = 0.2812, Top5 = 0.5469
Validation Accuracy Top1 = 0.3359, Top5 = 0.6484
Validation Accuracy Top1 = 0.2891, Top5 = 0.5938
Validation Accuracy Top1 = 0.2578, Top5 = 0.5312
Validation Accuracy Top1 = 0.2969, Top5 = 0.5703
Validation Accuracy Top1 = 0.2656, Top5 = 0.6094
Validation Accuracy Top1 = 0.2344, Top5 = 0.5547
Validation Accuracy Top1 = 0.3125, Top5 = 0.6094
Validation Accuracy Top1 = 0.3203, Top5 = 0.5859
Validation Accuracy Top1 = 0.3516, Top5 = 0.6172
Validation Accuracy Top1 = 0.3359, Top5 = 0.5312
Validation Accuracy Top1 = 0.3125, Top5 = 0.5938
Validation Accuracy Top1 = 0.3125, Top5 = 0.5625
Validation Accuracy Top1 = 0.2578, Top5 = 0.5391
Validation Accuracy Top1 = 0.2656, Top5 = 0.5234
Validation Accuracy Top1 = 0.2422, Top5 = 0.5781
Validation Accuracy Top1 = 0.3281, Top5 = 0.6016
Validation Accuracy Top1 = 0.2969, Top5 = 0.5547
Validation Accuracy Top1 = 0.3281, Top5 = 0.5781
Validation Accuracy Top1 = 0.2656, Top5 = 0.5859
Validation Accuracy Top1 = 0.3359, Top5 = 0.5781
Validation Accuracy Top1 = 0.2031, Top5 = 0.5625
Validation Accuracy Top1 = 0.2812, Top5 = 0.5312
Validation Accuracy Top1 = 0.2812, Top5 = 0.5938
Validation Accuracy Top1 = 0.3516, Top5 = 0.6953
Validation Accuracy Top1 = 0.2734, Top5 = 0.5938
Validation Accuracy Top1 = 0.2891, Top5 = 0.5625
Validation Accuracy Top1 = 0.2344, Top5 = 0.4922
Validation Accuracy Top1 = 0.2500, Top5 = 0.5547
Validation Accuracy Top1 = 0.2812, Top5 = 0.5156
Validation Accuracy Top1 = 0.2891, Top5 = 0.6172
Validation Accuracy Top1 = 0.3281, Top5 = 0.6016
Validation Accuracy Top1 = 0.3438, Top5 = 0.6953
Validation Accuracy Top1 = 0.2578, Top5 = 0.5781
Validation Accuracy Top1 = 0.3203, Top5 = 0.5859
Validation Accuracy Top1 = 0.4375, Top5 = 0.5938
Validation Accuracy Top1 = 0.2969, Top5 = 0.6641
Validation Accuracy Top1 = 0.3203, Top5 = 0.5625
Validation Accuracy Top1 = 0.3984, Top5 = 0.7031
Validation Accuracy Top1 = 0.3672, Top5 = 0.5859
Validation Accuracy Top1 = 0.2891, Top5 = 0.5078
Validation Accuracy Top1 = 0.3125, Top5 = 0.6562
Validation Accuracy Top1 = 0.2734, Top5 = 0.4766
Validation Accuracy Top1 = 0.2891, Top5 = 0.6484
Validation Accuracy Top1 = 0.3047, Top5 = 0.5938
Evaluation Finished! Accuracy Top1 = 0.2948, Top5 = 0.5817
